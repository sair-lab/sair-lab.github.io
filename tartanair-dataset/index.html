


<!DOCTYPE html>
<html>
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    
    <title>TartanAir: A Dataset to Push the Limits of Visual SLAM - Chen Wang</title>
    
    <link rel="stylesheet" href="/assets/css/app.css">

    <link rel="shortcut icon" type="image/ico" href="/img/favicon/favicon.ico" />

    <link rel="apple-touch-icon" sizes="180x180" href="/img/favicon/apple-touch-icon.png">
    <link rel="icon" type="image/png" sizes="32x32" href="/img/favicon/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="/img/favicon/favicon-16x16.png">
    <link rel="manifest" href="/img/favicon/site.webmanifest">
    <link rel="mask-icon" href="/img/favicon/safari-pinned-tab.svg" color="#cc002b">
    <meta name="msapplication-TileColor" content="#b91d47">
    <meta name="theme-color" content="#ffffff">

    <script defer src="https://use.fontawesome.com/releases/v5.3.1/js/all.js"></script>

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  
  <!-- Include the standard DataTables bits -->
  <link rel="stylesheet" type="text/css" href="//cdn.datatables.net/1.10.13/css/jquery.dataTables.css">
  <script type="text/javascript" charset="utf8" src="//cdn.datatables.net/1.10.13/js/jquery.dataTables.js"></script>
  <script>
    $(document).ready(function () {
      $('div.datatable-begin').nextUntil('div.datatable-end', 'table').addClass('display');
      $('table.display').DataTable({
        paging: false,
        stateSave: true,
        searching: true
      });
    });
  </script>
  
  
    <script>
      $(document).ready(function () {
          $('.content a').attr({'target':'_blank', 'rel':'noopener noreferrer'});
        });
    </script>
  

    <!-- Begin Jekyll SEO tag v2.7.1 -->
<title>TartanAir: A Dataset to Push the Limits of Visual SLAM | Chen Wang</title>
<meta name="generator" content="Jekyll v4.2.0" />
<meta property="og:title" content="TartanAir: A Dataset to Push the Limits of Visual SLAM" />
<meta name="author" content="Wenshan Wang" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="TartanAir" />
<meta property="og:description" content="TartanAir" />
<link rel="canonical" href="https://sairlab.org/tartanair-dataset/" />
<meta property="og:url" content="https://sairlab.org/tartanair-dataset/" />
<meta property="og:site_name" content="Chen Wang" />
<meta property="og:image" content="https://sairlab.org/img/posts/2020-02-29-tartanair/web_cover_figure.png" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2020-02-29T13:55:07+00:00" />
<meta name="twitter:card" content="summary_large_image" />
<meta property="twitter:image" content="https://sairlab.org/img/posts/2020-02-29-tartanair/web_cover_figure.png" />
<meta property="twitter:title" content="TartanAir: A Dataset to Push the Limits of Visual SLAM" />
<script type="application/ld+json">
{"author":{"@type":"Person","name":"Wenshan Wang"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://sairlab.org/tartanair-dataset/"},"description":"TartanAir","url":"https://sairlab.org/tartanair-dataset/","@type":"BlogPosting","image":"https://sairlab.org/img/posts/2020-02-29-tartanair/web_cover_figure.png","headline":"TartanAir: A Dataset to Push the Limits of Visual SLAM","dateModified":"2020-02-29T13:55:07+00:00","datePublished":"2020-02-29T13:55:07+00:00","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-84365303-1"></script>
<script>
  window['ga-disable-UA-84365303-1'] = window.doNotTrack === "1" || navigator.doNotTrack === "1" || navigator.doNotTrack === "yes" || navigator.msDoNotTrack === "1";
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());
  gtag('config', 'UA-84365303-1');
  gtag('config', 'G-ERWFHDG4GX');
</script><!-- head scripts --><!-- Added by Chen -->
    <script type='text/javascript' src='https://platform-api.sharethis.com/js/sharethis.js#property=5ee902d30e78e50012567eb4&product=inline-follow-buttons&cms=sop' async='async'></script>

    <!-- for mathjax support -->
    

</head>

<body>
    
<nav class="navbar is-primary" >
    <div class="container">
        <div class="navbar-brand">
            <a href="/" class="navbar-item navbar-logo">
                Chen Wang
            </a>
            <a role="button" class="navbar-burger burger" aria-label="menu" aria-expanded="false" data-target="navMenu">
                <span aria-hidden="true"></span>
                <span aria-hidden="true"></span>
                <span aria-hidden="true"></span>
            </a>
        </div>
        <div class="navbar-menu" id="navMenu">
            <div class="navbar-start">
                <a href="/" class="navbar-item ">Home</a>
                
                
                    
                    <a href="/experience/" class="navbar-item ">Experience</a>
                    
                
                    
                    <a href="/research/" class="navbar-item ">Research</a>
                    
                
                    
                    <a href="/publications/" class="navbar-item ">Publications</a>
                    
                
                    
                    <a href="/datasets/" class="navbar-item ">Datasets</a>
                    
                
                    
                    <a href="/contact/" class="navbar-item ">Contact</a>
                    
                
                
            </div>
        </div>
    </div>
</nav>
  <section class="hero  
        is-small 
         is-bold is-primary" 
        >
    <div class="hero-body">
        <div class="container">
            
                <p class="title is-2" style="color:white;">TartanAir: A Dataset to Push the Limits of Visual SLAM</p>
                <p class="subtitle is-3" style="color:white;"></p>
                <p class="subtitle is-3">
            
            
            
        </p>
        </div>
    </div>
</section>

<style>
    .button.is-info {
     background-color:#cc002b;
     border-color:transparent;
     color:#fff
    }
    .button.is-info.is-hovered {
     background-color:#cc002b;
     border-color:transparent;
     color:#fff
    }
</style>
  


    <section class="section">
        <div class="container">
            <div class="columns">
                

                
                <div class="column is-9">
                      
  <div style="text-align: center; display: block; margin-left:auto; margin-right:auto">
    <img style="text" src="/img/posts/2020-02-29-tartanair/web_cover_figure.png" alt="TartanAir: A Dataset to Push the Limits of Visual SLAM" />
</div>


<!-- Figure out the relative link to the author -->





	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	
		
			

<div class="content">

    <p><div style="font-size: 13px">Published: 
		<time datetime="2020-02-29T13:55:07+00:00">Feb 29, 2020</time> by 
		<div style="font-weight: bold; color: #3399ff; display: inline">
		
			<a href="/team/wenshan">Wenshan Wang</a>
		
		</div>
	</div></p>

    <!-- <h1>TartanAir: A Dataset to Push the Limits of Visual SLAM</h1> -->

    <div class="video-wrapper"><iframe src="https://www.youtube.com/embed/qDwfHvTbJx4" frameborder="0" allowfullscreen=""></iframe></div>

<h2 id="abstract">Abstract</h2>

<p>We present a challenging dataset, the TartanAir, for robot navigation task and more. The data is collected in photo-realistic simulation environments in the presence of various light conditions, weather and moving objects. By collecting data in simulation, we are able to obtain multi-modal sensor data and precise ground truth labels, including the stereo RGB image, depth image, segmentation, optical flow, camera poses, and LiDAR point cloud. We set up a large number of environments with various styles and scenes, covering challenging viewpoints and diverse motion patterns, which are difficult to achieve by using physical data collection platforms. In order to enable data collection in such large scale, we develop an automatic pipeline, including mapping, trajectory sampling, data processing, and data verification. We evaluate the impact of various factors on visual SLAM algorithms using our data. Results of state-of-the-art algorithms reveal that the visual SLAM problem is far from solved, methods that show good performance on established datasets such as KITTI donâ€™t perform well in more difficult scenarios. Although we use the simulation, our goal is to push the limits of Visual SLAM algorithms in the real world by providing a challenging benchmark for testing new methods, as well as large diverse training data for learning-based methods.</p>

<h2 id="citation">Citation</h2>

<p>Please read our <a href="https://arxiv.org/abs/2003.14338">paper</a> for details.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>@article{tartanair2020iros,
  title =   {TartanAir: A Dataset to Push the Limits of Visual SLAM},
  author =  {Wang, Wenshan and Zhu, Delong and Wang, Xiangwei and Hu, Yaoyu and Qiu, Yuheng and Wang, Chen and Hu, Yafei and Kapoor, Ashish and Scherer, Sebastian},
  booktitle = {2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  year =    {2020}
}
</code></pre></div></div>

<h2 id="download">Download</h2>

<p>The dataset is published using Azure Open Dataset platform. Please checkout <a href="https://github.com/castacks/tartanair_tools">here</a> for the instruction of accessing the data.</p>

<p>Sample trajectories can be downloaded here.</p>

<table>
  <tbody>
    <tr>
      <td><img src="/img/posts/2020-02-29-tartanair/abandonedfactory.gif" /> <br /> <a href="https://cmu.box.com/s/5ycmyx1q3vumesl0bozfze1a54ejwgmq">abandonedfactory</a></td>
      <td><img src="/img/posts/2020-02-29-tartanair/abandonedfactory_night.gif" /> <br /> <a href="https://cmu.box.com/s/zohqnu8mglwh4hw2zszxoqt69hc1pwha">abandonedfactory_night</a></td>
      <td><img src="/img/posts/2020-02-29-tartanair/amusement.gif" /> <br /> <a href="https://cmu.box.com/s/mn7z8dwr93wl23zngwi3q76kyq4dbkv7">amusement</a></td>
      <td><img src="/img/posts/2020-02-29-tartanair/carwelding.gif" /> <br /> <a href="https://cmu.box.com/s/qpoikn7owhhj2v718m8u9cdmpsqmuq14">carwelding</a></td>
    </tr>
    <tr>
      <td><img src="/img/posts/2020-02-29-tartanair/endofworld.gif" /> <br /> <a href="https://cmu.box.com/s/jk2pihbq94eicvd0vr7hjme26bn1u2tt">endofworld</a></td>
      <td><img src="/img/posts/2020-02-29-tartanair/gascola.gif" /> <br /> <a href="https://cmu.box.com/s/fxtytvvbbn0e2g9flhr2br1eiibj8dfs">gascola</a></td>
      <td><img src="/img/posts/2020-02-29-tartanair/hospital.gif" /> <br /> <a href="https://cmu.box.com/s/clj21v7ancdhxe6u87tp56b638e4rur0">hospital</a></td>
      <td><img src="/img/posts/2020-02-29-tartanair/jananesealley.gif" /> <br /> <a href="https://cmu.box.com/s/19aj7mob1s4912tmg36lotuiwgf0x5fh">japanesealley</a></td>
    </tr>
    <tr>
      <td><img src="/img/posts/2020-02-29-tartanair/neighborhood.gif" /> <br /> <a href="https://cmu.box.com/s/5trtb7f3ogjao33lgk6xu6t9y9nu79wg">neighborhood</a></td>
      <td><img src="/img/posts/2020-02-29-tartanair/ocean.gif" /> <br /> <a href="https://cmu.box.com/s/1egqcvrfqzg84ctpu81x2ww00y1xcpfv">ocean</a></td>
      <td><img src="/img/posts/2020-02-29-tartanair/office.gif" /> <br /> <a href="https://cmu.box.com/s/nem5fglri6fbfa0t5rm854l67q0fu0l9">office</a></td>
      <td><img src="/img/posts/2020-02-29-tartanair/seasidetown.gif" /> <br /> <a href="https://cmu.box.com/s/zzwyrrqm2ir2z0z75tqowpq91gny2sjk">seasidetown</a></td>
    </tr>
    <tr>
      <td><img src="/img/posts/2020-02-29-tartanair/seasonsforest.gif" /> <br /> <a href="https://cmu.box.com/s/nssib68sq3ilp0qy0r3zl347wtkophgb">seasonsforest</a></td>
      <td><img src="/img/posts/2020-02-29-tartanair/seasonsforest_winter.gif" /> <br /> <a href="https://cmu.box.com/s/lwrzi0d338857qy79odarmsgtbp5j0qg">seasonsforest_winter</a></td>
      <td><img src="/img/posts/2020-02-29-tartanair/soulcity.gif" /> <br /> <a href="https://cmu.box.com/s/cusfpmiskrgn8l3h0t1hivwt81mcfdk9">soulcity</a></td>
      <td><img src="/img/posts/2020-02-29-tartanair/westerndesert.gif" /> <br /> <a href="https://cmu.box.com/s/0dz8ybjgontw59k3g2s2l43b80hyk1u1">westerndesert</a></td>
    </tr>
  </tbody>
</table>

<!-- <img src="/img/posts/2020-02-29-tartanair/hongkongalley.gif" /> <br/> [hongkongalley](http://dummy) -->
<!-- <img src="/img/posts/2020-02-29-tartanair/house.gif" /> <br/> [house](http://dummy)  -->
<!-- <img src="/img/posts/2020-02-29-tartanair/oldtown.gif" /> <br/> [oldtown](http://dummy)  -->
<!-- <img src="/img/posts/2020-02-29-tartanair/slaughter.gif" /> <br/> [slaughter](http://dummy)  -->

<h2 id="the-mission">The mission</h2>

<p>Simultaneous Localization and Mapping (SLAM) is one of the most fundamental capabilities necessary for robots. Due to the ubiquitous availability of images, Visual SLAM (V-SLAM) has become an important component of many autonomous systems. Impressive progress has been made with both geometric-based methods and learning-based methods. However, developing robust and reliable SLAM methods for real-world applications is still a challenging problem. Real-life environments are full of difficult cases such as light changes or lack of illumination, dynamic objects, and texture-less scenes. Current popular benchmarks such as KITTI, TUM RGB-D SLAM datasets, and EuRoC MAV cover relatively limited scenarios and motion patterns compared to real-world cases.</p>

<p>We collect a large dataset using photo-realistic simulation environments. We minimize the sim2real gap by utilizing a large number of environments with various styles and diverse scenes. A special goal of our dataset is to focus on the challenging environments with changing light conditions, adverse weather, and dynamic objects. State-of-the-art SLAM algorithms are struggled in tracking the camera pose in our dataset and constantly getting lost on some challenging sequences. We propose a metric to evaluate the robustness of the algorithm. In addition, we develop an automatic data collection pipeline, which allows us to process more environments with minimum human intervention.</p>

<p>The four most important features of our dataset are:</p>

<ul>
  <li>Large size diverse realistic data</li>
  <li>Multimodal ground truth labels</li>
  <li>Diversity of motion patterns</li>
  <li>Challenging Scenes</li>
</ul>

<!-- <span style="color:red"> A youtube video should go here. </span> -->

<h2 id="dataset-features">Dataset features</h2>

<h3 id="simulated-scenes">Simulated scenes</h3>
<p>We have adopted 30 photo-realistic simulation environments in the <a href="https://www.unrealengine.com/">Unreal Engine</a>. The environments provide us a wide range of scenarios that cover many interesting yet challenging situations. The simulation scenes consist of</p>

<ul>
  <li>Indoor and outdoor scenes with detailed 3D objects. We have multi-room, richly decorated indoor environments. For outdoor simulations, there are various kinds of buildings, trees, terrains, and landscapes.</li>
  <li>Special purpose facilities and ordinary household scenes.</li>
  <li>Rural and urban scenes.</li>
  <li>Real-life and sci-fi scenes.</li>
</ul>

<figure>
 <img src="/img/posts/2020-02-29-tartanair/environments.png" alt="Simulated environments" />
 <figcaption>
 A glance of the simulated environments.
 </figcaption>
</figure>

<h3 id="challenging-visual-effects">Challenging visual effects</h3>
<p>In some simulations, we simulated multiple types of challenging visual effects.</p>

<ul>
  <li>Hard lighting conditions. Day-night alternating. Low-lighting. Rapidly changing illuminations.</li>
  <li>Weather effects. Clear, raining, snowing, windy, and fog.</li>
  <li>Seasonal change.</li>
</ul>

<figure>
 <img src="/img/posts/2020-02-29-tartanair/visual_effects.png" alt="The challenging visual effects." />
 <figcaption>
 Challenging visual effects.
 </figcaption>
</figure>

<h3 id="diverse-ego-motions">Diverse ego motions</h3>

<p>In each simulated environment, we gather data by following multiple routes and making movements with different levels of aggressiveness. The virtual camera can move slowly and smoothly without sudden jittering actions. Or it can have intensive and violent actions mixed with significant rolling and yaw motions.</p>

<h3 id="multimodal-ground-truth-labels">Multimodal ground truth labels</h3>

<p>By unleashing the power of the <a href="https://www.unrealengine.com/">Unreal Engine</a> and <a href="https://github.com/microsoft/AirSim">AirSim</a>, we can extract various types of ground truth labels including depth, semantic segmentation tag, and camera pose. From the extracted raw data, we further compute other ground truth labels such as optical flow, stereo disparity, simulated multi-line LiDAR points, and simulated IMU readings.</p>

<figure>
 <img src="/img/posts/2020-02-29-tartanair/multimodal_data_20200301.png" alt="Data and ground truth labels." />
 <figcaption>
 Data and ground truth labels.
 </figcaption>
</figure>

<h2 id="data-acquisition-pipeline">Data acquisition pipeline</h2>

<p>We develop a highly automated pipe-line to facilitate data acquisition. For each environment, we build an occupancy map by incremental mapping. Base on the map, we then sample a bunch of trajectories for the virtual camera to follow. A set of virtual cameras follow the trajectories to capture raw data from Unreal Engine and AirSim. Raw data are processed to generate labels such as optical flow, stereo disparity, simulated LiDAR points, and simualated IMU readings. Data verification. Verify the data synchronization and the accuracy of the derived labels.</p>

<figure>
 <img src="/img/posts/2020-02-29-tartanair/pipeline_20200301.png" alt="Data acquisition pipeline." />
 <figcaption>
 Data acquisition pipeline.
 </figcaption>
</figure>

<!-- **<span style="color: #800000;">Please refer to the *Download* section below to download the dataset and the code.</span>**
 -->
<h3 id="contact">Contact</h3>

<p>Email tartanair@hotmail.com if you have any questions about the data source. You can also reach out to contributors on the associated [GitHub}(https://github.com/microsoft/AirSim).</p>

<p>Wenshan Wang - (wenshanw [at] andrew [dot] cmu [dot] edu)</p>

<p>Sebastian Scherer - (basti [at] cmu [dot] edu)</p>

<h3 id="acknowledgments">Acknowledgments</h3>

<p>This work was supported by Office of Naval Research under award number N0014-19-1-2266. We thank Ratnesh Madaan, Guada Casuso, Rashaud Savage and other team members from Microsoft for the technical support!</p>

<h3 id="term-of-use">Term of use</h3>

<p><a rel="license" href="http://creativecommons.org/licenses/by/4.0/"><img alt="Creative Commons License" style="border-width:0" src="https://i.creativecommons.org/l/by/4.0/80x15.png" /></a><br />This work is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution 4.0 International License</a>.</p>

</div>

<div class="tags">
    
</div>



                </div>
                
                <div class="column is-3-desktop is-12-tablet">
                    <p class="title is-4">Latest News</p>

<!-- <div class="columns is-multiline">
    
    <div class="column is-12">
        <a href="/airobject/">
<div class="card" style="height: 100%; display: flex; flex-direction: column; align-items: center;">
    
        <div style="height: 200px;">
            <img src="/img/posts/2022-03-15-airobject/obj_1_org.gif" alt="AirObject: A Temporally Evolving Graph Embedding for Object Identification" style="object-fit: contain; height: 100%;">
        </div>
    
    <div class="card-content" style="flex-grow: 3;">
        <div class="content">
            
            <div class="title is-5">AirObject: A Temporally Evolving Graph Embedding for Object Identification</div>
            
            <p>               Video Object Identification    </p>
        </div>
    </div>
    <footer class="card-footer">
        <p class="card-footer-item">Published: Mar 15, 2022</p>
    </footer>
</div>
</a>

    </div>
    
    <div class="column is-12">
        <a href="/lgl/">
<div class="card" style="height: 100%; display: flex; flex-direction: column; align-items: center;">
    
        <div style="height: 200px;">
            <img src="/img/posts/2022-03-05-lgl/matching.jpg" alt="Lifelong Graph Learning" style="object-fit: contain; height: 100%;">
        </div>
    
    <div class="card-content" style="flex-grow: 3;">
        <div class="content">
            
            <div class="title is-5">Lifelong Graph Learning</div>
            
            <p>Graph neural networks (GNNs) are powerful models for many graph-structured tasks. Existing models...</p>
        </div>
    </div>
    <footer class="card-footer">
        <p class="card-footer-item">Published: Mar 5, 2022</p>
    </footer>
</div>
</a>

    </div>
    
    <div class="column is-12">
        <a href="/airdos">
<div class="card" style="height: 100%; display: flex; flex-direction: column; align-items: center;">
    
        <div style="height: 200px;">
            <img src="/img/posts/2022-02-06-airdos/AirDOS-title.gif" alt="AirDOS: Dynamic SLAM benefits from Articulated Objects" style="object-fit: contain; height: 100%;">
        </div>
    
    <div class="card-content" style="flex-grow: 3;">
        <div class="content">
            
            <div class="title is-5">AirDOS: Dynamic SLAM benefits from Articulated Objects</div>
            
            <p>Dynamic Object-aware SLAM (DOS) exploits object-level information to enable robust motion estimat...</p>
        </div>
    </div>
    <footer class="card-footer">
        <p class="card-footer-item">Published: Feb 6, 2022</p>
    </footer>
</div>
</a>

    </div>
    
</div> -->

<a class="twitter-timeline"
data-tweet-limit="8"
data-theme="light"
width="100%"
href="https://twitter.com/DrChenWang">
News from Twitter @DrChenWang<br>You need VPN if you see this.
</a>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>


                </div>
                
            </div>
        </div>
    </section>
     <style>
  #blocks {
      width:100%;
      height:60px;
      margin:0 auto;
      /* background-color: #ffe; */
  }
  #block1 {
      height:33.33%;
      width:30%;
      /* background: red; */
      float: left;
  }
  #block2 {
      height:33.33%;
      width:40%;
      /* background: yellow; */
      float: left;
  }
  #block3 {
      height:33.33%;
      width:30%;
      /* background: green; */
      float: right;
  }
</style>

<link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">

<footer class="footer">
    <div class="container">
        <!-- 
        <div class="columns is-multiline">
            
            <div class="column has-text-centered">
                <div>
                    <a href="/" class="link">Home</a>
                </div>
            </div>
            
            <div class="column has-text-centered">
                <div>
                    <a href="/blog/" class="link">Blog</a>
                </div>
            </div>
            
            <div class="column has-text-centered">
                <div>
                    <a href="/products/" class="link">Products</a>
                </div>
            </div>
            
            <div class="column has-text-centered">
                <div>
                    <a href="/privacy-policy/" class="link">Privacy Policy</a>
                </div>
            </div>
            
        </div>
         -->
        <div id="blocks">
          <div id="block1"><img src="/img/logos/cmu-wordmark-stacked-r.png" alt="AirLab Logo" style="height:60px;"></div>
          <div id="block2">
            <center>

              <!-- <a class="button" itemprop="email" href="https://www.facebook.com" target="_blank">
                <i class="fab fa-github"></i>
              </a> -->
              <!-- <a class="button" itemprop="email" href="https://www.facebook.com" target="_blank">
                <i class="fab fa-facebook"</i>
              </a> -->
              <!-- <a class="button" itemprop="facebook" href="https://www.facebook.com/airlabcmu/" target="_blank">
                <i class="fab fa-facebook fa-lg" style="height:100%;"></i>
              </a> -->
              <a class="button" itemprop="github" href="https://scholar.google.com/citations?user=vZfmKl4AAAAJ&hl=en" target="_blank">
                <i class="ai ai-google-scholar ai-2x"></i>
              </a>
              <a class="button" itemprop="github" href="https://github.com/wang-chen" target="_blank">
                <i class="fab fa-github fa-lg"></i>
              </a>
              <a class="button" itemprop="linkedin" href="https://www.linkedin.com/in/wang-chen" target="_blank">
                <i class="fab fa-linkedin fa-lg"></i>
              </a>
              <a class="button" itemprop="twitter" href="https://www.twitter.com/DrChenWang/" target="_blank">
                <i class="fab fa-twitter fa-lg"></i>
              </a>
              <!-- <a class="button" itemprop="medium" href="https://medium.com/airlabcmu" target="_blank">
                <i class="fab fa-medium fa-lg"></i>
              </a> -->
              <a class="button" itemprop="youtube" href="https://www.youtube.com/channel/UCA-y9bZJsV9JAHQ9VnRBplg/videos" target="_blank">
                <i class="fab fa-youtube fa-lg"></i>
              </a>
              <!-- <a class="button" itemprop="bitbucket" href="https://bitbucket.org/castacks/" target="_blank"> -->
                <!-- <i class="fab fa-bitbucket fa-lg"></i> -->
              <!-- </a> -->
              <br>
              <br>
              <!-- <p class="">&copy; 2021 | Built using the <a href="https://github.com/chrisrhymes/bulma-clean-theme">Bulma Clean Theme</a></p> -->
            </center>
          </div>
          <div id="block3"><img src="/img/logos/RI_small.jpeg" alt="RI Logo" style="float:right;height:60px;"></div>
        </div>
        <!-- <div>
          <a href="" class="button is-large"><div class="icon"><i class="fab fa-facebook"</i></div></a>
        </div> -->
        <!-- <div class="content is-small has-text-centered">
            <p class="">Â© 2020</p>
        </div> -->
    </div>


</footer>
 
    <script src="/assets/js/app.js" type="text/javascript"></script><!-- footer scripts --></body>

</html>
